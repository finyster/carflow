# plot_trajectories.py (v4.1 - äº’å‹•å¼ + æ–¹å‘æŒ‡ç¤ºå„ªåŒ–)
import cv2
import json
import numpy as np
import argparse
import yaml

# --- å…¨åŸŸè®Šæ•¸ ---
current_filter = None
redraw_flag = True

# --- è¼”åŠ©å‡½å¼ ---
def get_color(cls):
    pal = {"car": (0, 255, 255), "bus": (255, 0, 0), "truck": (0, 0, 255), "motorcycle": (0, 255, 0)}
    return pal.get(cls, (200, 200, 200))

def mouse_callback(event, x, y, flags, param):
    """è™•ç†æ»‘é¼ é»æ“Šäº‹ä»¶ï¼Œæª¢æŸ¥æ˜¯å¦é»æ“Šåœ¨æŒ‰éˆ•ä¸Š"""
    global current_filter, redraw_flag
    buttons = param['buttons']
    if event == cv2.EVENT_LBUTTONDOWN:
        for btn_name, rect in buttons.items():
            if rect[0] <= x <= rect[2] and rect[1] <= y <= rect[3]:
                if btn_name == 'All':
                    current_filter = None
                    print("âœ… å·²é¸æ“‡é¡¯ç¤º [å…¨éƒ¨] è»Šç¨®")
                else:
                    current_filter = [btn_name]
                    print(f"âœ… å·²é¸æ“‡åªé¡¯ç¤º [{btn_name}]")
                redraw_flag = True
                break

def main(track_file, background_mode, output_image, video_path=None):
    # --- è¼‰å…¥èƒŒæ™¯åœ–ç‰‡ ---
    bg_img = None
    if background_mode in ['video', 'black', 'white']:
        if not video_path: print("âŒ éŒ¯èª¤ï¼šä½¿ç”¨ 'video', 'black', æˆ– 'white' æ¨¡å¼æ™‚ï¼Œå¿…é ˆæä¾› --video åƒæ•¸ï¼"); return
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened(): print(f"âŒ éŒ¯èª¤ï¼šç„¡æ³•é–‹å•Ÿå½±ç‰‡æª”æ¡ˆï¼è·¯å¾‘: {video_path}"); return
        W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)); H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        if background_mode == 'video':
            ret, frame = cap.read(); bg_img = frame
            if not ret: print("âŒ éŒ¯èª¤ï¼šç„¡æ³•è®€å–å½±ç‰‡çš„ç¬¬ä¸€å¹€ï¼"); cap.release(); return
        else:
            color = (0, 0, 0) if background_mode == 'black' else (255, 255, 255)
            bg_img = np.full((H, W, 3), color, dtype=np.uint8)
        cap.release()
    else:
        try: bg_img = cv2.imread(background_mode); assert bg_img is not None
        except: print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æŒ‡å®šçš„èƒŒæ™¯åœ–ç‰‡æª”æ¡ˆï¼è·¯å¾‘: {background_mode}"); return

    # --- è¼‰å…¥è»Œè·¡æ•¸æ“š ---
    try:
        with open(track_file, 'r') as f: trajectories = json.load(f)
    except FileNotFoundError: print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è»Œè·¡æ•¸æ“šæª”æ¡ˆï¼è·¯å¾‘: {track_file}"); return

    # --- å»ºç«‹ UI æŒ‰éˆ• ---
    all_classes = sorted(list(set(info['class'] for info in trajectories.values() if info.get('class'))))
    button_names = ['All'] + all_classes
    buttons = {}
    btn_x, btn_y, btn_w, btn_h = 20, 20, 150, 40
    for i, name in enumerate(button_names):
        x1 = btn_x + i * (btn_w + 10)
        y1 = btn_y
        buttons[name] = (x1, y1, x1 + btn_w, y1 + btn_h)

    # --- ä¸»è¿´åœˆèˆ‡äº‹ä»¶è™•ç† ---
    window_name = "Interactive Trajectory Analyzer"
    cv2.namedWindow(window_name)
    cv2.setMouseCallback(window_name, mouse_callback, {'buttons': buttons})

    print("\n--- äº’å‹•æ“ä½œèªªæ˜ ---")
    print("ğŸ‘‰ åœ¨ä¸Šæ–¹é¸æ“‡è»Šç¨®æŒ‰éˆ•ï¼Œå³å¯ç¯©é¸é¡¯ç¤ºçš„è»Œè·¡ã€‚")
    print("ğŸ‘‰ æŒ‰ 's' éµå„²å­˜ç›®å‰çš„ç•«é¢ã€‚")
    print("ğŸ‘‰ æŒ‰ 'q' éµæˆ– Esc é›¢é–‹ã€‚")

    global redraw_flag
    while True:
        if redraw_flag:
            display_frame = bg_img.copy()

            for name, rect in buttons.items():
                color = (0, 255, 0) if (current_filter is None and name == 'All') or (current_filter and name in current_filter) else (80, 80, 80)
                cv2.rectangle(display_frame, (rect[0], rect[1]), (rect[2], rect[3]), color, -1)
                cv2.putText(display_frame, name, (rect[0] + 10, rect[3] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
                
            plot_count = 0
            for track_id, info in trajectories.items():
                vehicle_class = info.get("class")
                track_points = info.get("track")
                if not vehicle_class or not track_points or len(track_points) < 5: continue # å»ºè­°è»Œè·¡è‡³å°‘æœ‰5å€‹é»ï¼Œè®“ç®­é ­æ–¹å‘æ›´ç©©å®š

                if current_filter is None or vehicle_class in current_filter:
                    color = get_color(vehicle_class)
                    pts = np.array(track_points, np.int32).reshape((-1, 1, 2))
                    cv2.polylines(display_frame, [pts], isClosed=False, color=color, thickness=2)

                    # ç¹ªè£½èµ·é»åœ“åœˆ
                    start_point = tuple(track_points[0])
                    cv2.circle(display_frame, start_point, 7, color, -1)
                    
                    # âœ¨ã€æ ¸å¿ƒä¿®æ”¹ã€‘âœ¨ è®“çµ‚é»ç®­é ­æ›´æ¸…æ™°å¯è¦‹
                    # ç‚ºäº†è®“ç®­é ­æ–¹å‘æ›´ç©©å®šï¼Œæˆ‘å€‘å–è»Œè·¡çš„æœ€å¾Œå¹¾å€‹é»ä¾†è¨ˆç®—
                    end_point = tuple(track_points[-1])
                    prev_point = tuple(track_points[-5]) # å–å€’æ•¸ç¬¬5å€‹é»ï¼Œè®“ç®­é ­çš„å‘é‡æ›´é•·ã€æ–¹å‘æ›´æº–

                    # å¢åŠ ç·šæ¢ç²—ç´° (4)ï¼Œä¸¦å¢å¤§ç®­é ­æ¯”ä¾‹ (0.5)
                    cv2.arrowedLine(display_frame, prev_point, end_point, color, 4, tipLength=0.5)

                    plot_count += 1
            
            redraw_flag = False

        cv2.imshow(window_name, display_frame)

        key = cv2.waitKey(20) & 0xFF
        if key == ord('q') or key == 27:
            break
        elif key == ord('s'):
            cv2.imwrite(output_image, display_frame)
            print(f"ğŸ–¼ï¸ ç•«é¢å·²å„²å­˜è‡³: {output_image}")

    cv2.destroyAllWindows()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="äº’å‹•å¼è»Œè·¡åˆ†æå„€")
    parser.add_argument("--tracks", default="results/trajectories_complex-2.json", help="å„²å­˜è»Œè·¡çš„ JSON æª”æ¡ˆè·¯å¾‘")
    parser.add_argument("--background", default="video", help="èƒŒæ™¯æ¨¡å¼: 'video', 'black', 'white', æˆ–åœ–ç‰‡æª”æ¡ˆè·¯å¾‘")
    parser.add_argument("--output", default="results/interactive_plot.jpg", help="æŒ‰ä¸‹ 's' éµæ™‚ï¼Œå„²å­˜çš„åœ–ç‰‡æª”å")
    parser.add_argument("--video", help="åŸå§‹å½±ç‰‡è·¯å¾‘ (ä½¿ç”¨ 'video', 'black', 'white' æ¨¡å¼æ™‚éœ€è¦)")
    
    args = parser.parse_args()
    
    if args.background in ['video', 'black', 'white'] and not args.video:
        try:
            with open("config.yaml") as f: cfg = yaml.safe_load(f)
            args.video = cfg.get("video_path")
            if not args.video: raise ValueError("config.yaml ä¸­æœªæ‰¾åˆ° video_path")
            print(f"â„¹ï¸ å·²å¾ config.yaml è‡ªå‹•è®€å–å½±ç‰‡è·¯å¾‘: {args.video}")
        except Exception as e: print(f"âŒ éŒ¯èª¤ï¼šå¿…é ˆæä¾› --video åƒæ•¸ã€‚ ({e})"); exit()
    
    main(args.tracks, args.background, args.output, args.video)